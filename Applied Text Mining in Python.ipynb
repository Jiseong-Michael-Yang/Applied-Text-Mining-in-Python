{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Text Mining in Python\n",
    "**<div style=\"text-align: right\">Jiseong Yang</div>**  \n",
    "**<font color='red'>Note</font>**: This is my personal lecture note based on [Applied Text Mining in Python](https://www.coursera.org/learn/python-text-mining) on [Coursera](https://www.coursera.org/) provided by University of Michigan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1: Working with Text in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Text in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Characters and Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethics are built right into the ideals and objectives of the United Nations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Characters\n",
    "text1= \"Ethics are built right into the ideals and objectives of the United Nations.\"; print(text1)\n",
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ethics', 'are', 'built', 'right', 'into', 'the', 'ideals', 'and', 'objectives', 'of', 'the', 'United', 'Nations.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words\n",
    "text2 = text1.split(\" \"); print(text2)\n",
    "len(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Specific Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics',\n",
       " 'built',\n",
       " 'right',\n",
       " 'into',\n",
       " 'ideals',\n",
       " 'objectives',\n",
       " 'United',\n",
       " 'Nations.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Long words: Words taht are more than 3 letters long\n",
    "[w for w in text2 if len(w) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics', 'United', 'Nations.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capitalized words\n",
    "[w for w in text2 if w.istitle()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics', 'ideals', 'objectives']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words that end with s\n",
    "[w for w in text2 if w.endswith('s')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To', 'be', 'or', 'not', 'to', 'be']\n",
      "6\n",
      "5\n",
      "['to', 'be', 'or', 'not', 'to', 'be']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Finding unique words\n",
    "text3 = \"To be or not to be\"\n",
    "text4 = text3.split(\" \"); print(text4)\n",
    "print(len(text4))\n",
    "print(len(set(text4)))\n",
    "print([w.lower() for w in text4])\n",
    "print(len(set(text4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Comparison Functions\n",
    "* s.startswith(t)\n",
    "* s.endswith(t)\n",
    "* t in s\n",
    "* s.isupper(); s.islower(); s.istitle()   \n",
    "e.g UPPER, lower, Title\n",
    "* s.isalpha(); s.isdigit(); s.isalnum()  \n",
    "e.g abcd, 1234, ab12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String Operations\n",
    "* s.lower(); s.upper(); s.titlecase()\n",
    "* s.split(t)\n",
    "* s.splitlines() - split sentence by '\\n'\n",
    "* s.join(t)\n",
    "* s.strip(); s.rstrip()\n",
    "* s.find(t); s.rfind(t)\n",
    "* s.replace(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'agad', 'g', '']\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "text5 = \"ouagadougou\"\n",
    "text6 = text5.split(\"ou\"); print(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ouagadougou'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join\n",
    "'ou'.join(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty separator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-03d52f60b264>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get all characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtext5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: empty separator"
     ]
    }
   ],
   "source": [
    "# Get all characters\n",
    "text5.split(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the characters\n",
    "print(list(text5))\n",
    "print([c for c in text5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whitespaces\n",
    "text8 = \"        A quick brown fox jumped over the lazy dog.    \"\n",
    "text8.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip\n",
    "text9 = text8.strip()\n",
    "text9.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find returns the number of the target string\n",
    "text9\n",
    "text9.find('o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace\n",
    "text9.replace(\"o\", \"O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Larger Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory\n",
    "import os\n",
    "wd = r\"C:\\Users\\Jiseong Yang\\Documents\\Jiseong Yang\\Scholar\\SKKU\\Semesters\\Thesis\\Lectures\\Applied Text Mining in Python\"\n",
    "os.chdir(wd)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files line by line\n",
    "f = open('UNDHR.txt', 'r')\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the full file\n",
    "f.seek(0) # Move to 0th byte.\n",
    "text12 = f.read()\n",
    "print(len(text12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitlines\n",
    "text13 = text12.splitlines()\n",
    "len(text13)\n",
    "print(text13)\n",
    "text13[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Operations\n",
    "* f = open(filename, mode)\n",
    "* f.readline() - read one line\n",
    "* f.read() - read the whole file\n",
    "* f.read(n) - read n character(s)\n",
    "* for line in f\n",
    "* f.seek(n)\n",
    "* f.write(message)\n",
    "* f.close()\n",
    "* f.closed - check if closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issues with Reading Text Files\n",
    "f = open(\"UNDHR.txt\", 'r')\n",
    "text14 = f.readline()\n",
    "text14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Newline Character\n",
    "text14.rstrip\n",
    "\n",
    "# Works also for DOS newlines (^M) that shows up as '\\r' or '\\r\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working With Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text separation\n",
    "text1 = \"Ethics are built right into the ideals and objectives of the United Nations \"\n",
    "len(text1) # The length of text1\n",
    "text2 = text1.split(' ') # Return a list of the words in text2, separating by ' '.\n",
    "len(text2)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find words that are greater than 3 letters\n",
    "[w for w in text2 if len(w) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics', 'United', 'Nations.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find words that are capitalized\n",
    "[w for w in text2 if w.istitle()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics', 'ideals', 'objectives']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find words that end with 's'\n",
    "[w for w in text2 if w.endswith('s')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To', 'be', 'or', 'not', 'to', 'be']\n"
     ]
    }
   ],
   "source": [
    "# Find qnique words\n",
    "text3 = \"To be or not to be\"\n",
    "text4 = text3.split(\" \")\n",
    "print(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'be', 'not', 'or', 'to'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower down the case\n",
    "set([w.lower() for w in text4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing Free-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Ethics', 'are', 'built', 'right', 'into', 'the', 'ideals', 'and', 'objectives', 'of', 'the', 'United', 'Nations\"', '#UNSG', '@', 'NY', 'Society', 'for', 'Ethical', 'Culture', 'bit.ly/2guVelr']\n"
     ]
    }
   ],
   "source": [
    "# Text Speration\n",
    "text5 = '\"Ethics are built right into the ideals and objectives of the United Nations\" \\\n",
    "#UNSG @ NY Society for Ethical Culture bit.ly/2guVelr'\n",
    "text6 = text5.split(' ')\n",
    "print(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#UNSG']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding hashtags\n",
    "[w for w in text6 if w.startswith(\"#\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding callouts\n",
    "[w for w in text6 if w.startswith(\"@\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Necessitiy of Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@UN', '@UN_Women', '\"Ethics', 'are', 'built', 'right', 'into', 'the', 'ideals', 'and', 'objectives', 'of', 'the', 'United', 'Nations\"', '#UNSG', '@', 'NY', 'Society', 'for', 'Ethical', 'Culture', 'bit.ly/2guVelr']\n"
     ]
    }
   ],
   "source": [
    "# Text separation\n",
    "text7 = '@UN @UN_Women \"Ethics are built right into the ideals and objectives of the United Nations\" \\\n",
    "#UNSG @ NY Society for Ethical Culture bit.ly/2guVelr'\n",
    "text8 = text7.split(' ')\n",
    "print(text8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@UN', '@UN_Women', '@']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding callouts\n",
    "[w for w in text8 if w.startswith('@')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@UN', '@UN_Women']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding callout with regular expressions\n",
    "import re\n",
    "[w for w in text8 if re.search('@[A-Za-z0-9_]+', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `[A-Za-z0-9_]+` will return all words that: \n",
    "    * start with `'@'` and are followed by at least one: \n",
    "    * capital letter (`'A-Z'`)\n",
    "    * lowercase letter (`'a-z'`) \n",
    "    * number (`'0-9'`)\n",
    "    * or underscore (`'_'`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Meta-characters\n",
    "\n",
    "* Character Symbols\n",
    "    * `.`: wildcard, matches a single character\n",
    "    * `^`: start of a string\n",
    "    * `$`: end of a string\n",
    "    * `[]`: matches one of the set of characters within []\n",
    "    * `[a-z]`: matches one of the range of character**s** a, b, ..., z\n",
    "    * `[^abc]`: matches **a** character that is not a, b, or, c\n",
    "    * `a|b`: mathes either a or b, where a and b are strings\n",
    "    * `()`: Scoping for operators\n",
    "    * `\\`: Escape character for special characters (\\t, \\n, \\b)\n",
    "    * `\\b`: matches word boundary\n",
    "    * `\\d`: any digit, equivalant to [0-9]\n",
    "    * `\\D`: any non-digit, equivalant to [^0-9]\n",
    "    * `\\s`: any whitespance, equivalant to [ \\t\\n\\r\\f\\v]\n",
    "    * `\\S`: any non-whitespance, equivalant to [^ \\t\\n\\r\\f\\v]\n",
    "    * `\\w`: alphaneumeric character, equivalanet to [a-zA-Z0-9_]\n",
    "    * `\\W`: non-alphaneumeric character, equivalanet to [^a-zA-Z0-9_]\n",
    "\n",
    "* Repetitions\n",
    "    * `*`: matches zero or more occurences\n",
    "    * `+`: matches one or more occurences\n",
    "    * `?`: matches zero or one occuerences\n",
    "    * `{n}`: exactly n repetitions, nâ‰¥0\n",
    "    * `{n,}`: at least n repetitions\n",
    "    * `{,n}`: at most n repetitions\n",
    "    * `{m,n}`: at least m and at most n repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'u', 'a', 'a', 'o', 'u', 'o', 'u']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find only vowels\n",
    "text12 = \"ouagadougou\"\n",
    "re.findall(r'[aeiou]', text12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g', 'd', 'g']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FInd only consnanats\n",
    "re.findall(r'[^aeiou]', text12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Study: Regular Expression for Dates\n",
    "* Date variations for 23rd October 2002  \n",
    "    * 23-13-1002\n",
    "    * 23/10/2002\n",
    "    * 23/10/02\n",
    "    * 10/23/2002\n",
    "    * 23 Oct 2002\n",
    "    * 23 October 2002\n",
    "    * Oct 23, 2002\n",
    "    * October 23, 2002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-13-1002\n",
      "23/10/2002\n",
      "23/10/02\n",
      "10/23/2002\n",
      "23 Oct 2002\n",
      "23 October 2002\n",
      "Oct 23, 2002\n",
      "October 23, 2002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Date Structures\n",
    "dateStr = '23-13-1002\\n23/10/2002\\n23/10/02\\n10/23/2002\\n23 Oct 2002\\n23 October 2002\\nOct 23, 2002\\nOctober 23, 2002\\n'\n",
    "print(dateStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group 1 (23-13-1002, 23/10/2002, 23/10/02, 10/23/2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23-13-1002', '23/10/2002', '23/10/02', '10/23/2002']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XX/-XX/-XXXX\n",
    "re.findall(r'\\d{2}[/-]\\d{2}[/-]\\d{4}', dateStr)\n",
    "\n",
    "# XX/-XX/-XX(XX)\n",
    "re.findall(r'\\d{2}[/-]\\d{2}[/-]\\d{2,4}', dateStr)\n",
    "\n",
    "# X(X)/-X(X)/-XX(XX)\n",
    "re.findall(r'\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}', dateStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group 2 (23 Oct 2002, 23 October 2002, Oct 23, 2002, October 23, 2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oct']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Mon)\n",
    "re.findall(r'\\d{2} (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23 Oct 2002']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XX (Mon) XXXX\n",
    "re.findall(r'\\d{2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23 Oct 2002', '23 October 2002']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XX ((Mon)th) XXXX \n",
    "re.findall(r'\\d{2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23 Oct 2002', '23 October 2002', 'Oct 23, 2002', 'October 23, 2002']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XX ((Mon)th) XX, (XXXX)\n",
    "re.findall(r'(?:\\d{2} )?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* (?:\\d{2}, )?\\d{4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23 Oct 2002', '23 October 2002', 'Oct 23, 2002', 'October 23, 2002']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X(X) ((Mon)th) X(X), (XXXX)\n",
    "re.findall(r'(?:\\d{1,2} )?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* (?:\\d{1,2}, )?\\d{4}', dateStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Text Data in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday: The doctor's appointment is at 2:45pm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday: The dentist's appointment is at 11:30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday: At 7:00pm, there is a basketball game!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday: Be back home by 11:15 pm at the latest.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday: Take the train at 08:10 am, arrive at ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0     Monday: The doctor's appointment is at 2:45pm.\n",
       "1  Tuesday: The dentist's appointment is at 11:30...\n",
       "2  Wednesday: At 7:00pm, there is a basketball game!\n",
       "3  Thursday: Be back home by 11:15 pm at the latest.\n",
       "4  Friday: Take the train at 08:10 am, arrive at ..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "time_sentences = [\"Monday: The doctor's appointment is at 2:45pm.\", \n",
    "                  \"Tuesday: The dentist's appointment is at 11:30 am.\",\n",
    "                  \"Wednesday: At 7:00pm, there is a basketball game!\",\n",
    "                  \"Thursday: Be back home by 11:15 pm at the latest.\",\n",
    "                  \"Friday: Take the train at 08:10 am, arrive at 09:00am.\"]\n",
    "\n",
    "df = pd.DataFrame(time_sentences, columns=['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    46\n",
       "1    50\n",
       "2    49\n",
       "3    49\n",
       "4    54\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of characters for each string in df['text']\n",
    "df['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     7\n",
       "1     8\n",
       "2     8\n",
       "3    10\n",
       "4    10\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of tokens for each string in df['text']\n",
    "df['text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: text, dtype: bool"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find which entries contain the word 'appointment'\n",
    "df['text'].str.contains('appointment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    4\n",
       "2    3\n",
       "3    4\n",
       "4    8\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find how many times a digit occurs in each string\n",
    "df['text'].str.count(r'\\d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   [2, 4, 5]\n",
       "1                [1, 1, 3, 0]\n",
       "2                   [7, 0, 0]\n",
       "3                [1, 1, 1, 5]\n",
       "4    [0, 8, 1, 0, 0, 9, 0, 0]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all occurances of the digits\n",
    "df['text'].str.findall(r'\\d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               [(2, 45)]\n",
       "1              [(11, 30)]\n",
       "2               [(7, 00)]\n",
       "3              [(11, 15)]\n",
       "4    [(08, 10), (09, 00)]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group and find the hours and minutes\n",
    "df['text'].str.findall(r'(\\d?\\d):(\\d\\d)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          ???: The doctor's appointment is at 2:45pm.\n",
       "1       ???: The dentist's appointment is at 11:30 am.\n",
       "2          ???: At 7:00pm, there is a basketball game!\n",
       "3         ???: Be back home by 11:15 pm at the latest.\n",
       "4    ???: Take the train at 08:10 am, arrive at 09:...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace weekdays with '???'\n",
    "df['text'].str.replace(r'\\w+day\\b', '???')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Mon: The doctor's appointment is at 2:45pm.\n",
       "1       Tue: The dentist's appointment is at 11:30 am.\n",
       "2          Wed: At 7:00pm, there is a basketball game!\n",
       "3         Thu: Be back home by 11:15 pm at the latest.\n",
       "4    Fri: Take the train at 08:10 am, arrive at 09:...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace weekdays with 3 letter abbrevations\n",
    "df['text'].str.replace(r'(\\w+day\\b)', lambda x: x.groups()[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0   2  45\n",
       "1  11  30\n",
       "2   7  00\n",
       "3  11  15\n",
       "4  08  10"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new columns from first match of extracted groups\n",
    "df['text'].str.extract(r'(\\d?\\d):(\\d\\d)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2:45pm</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>11:30 am</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>7:00pm</td>\n",
       "      <td>7</td>\n",
       "      <td>00</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>11:15 pm</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>08:10 am</td>\n",
       "      <td>08</td>\n",
       "      <td>10</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09:00am</td>\n",
       "      <td>09</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0   1   2   3\n",
       "  match                      \n",
       "0 0        2:45pm   2  45  pm\n",
       "1 0      11:30 am  11  30  am\n",
       "2 0        7:00pm   7  00  pm\n",
       "3 0      11:15 pm  11  15  pm\n",
       "4 0      08:10 am  08  10  am\n",
       "  1       09:00am  09  00  am"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the entire time, the hours, the minutes, and the period\n",
    "df['text'].str.extractall(r'((\\d?\\d):(\\d\\d) ?([ap]m))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2:45pm</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>11:30 am</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>7:00pm</td>\n",
       "      <td>7</td>\n",
       "      <td>00</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>11:15 pm</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>08:10 am</td>\n",
       "      <td>08</td>\n",
       "      <td>10</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09:00am</td>\n",
       "      <td>09</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time hour minute period\n",
       "  match                             \n",
       "0 0        2:45pm    2     45     pm\n",
       "1 0      11:30 am   11     30     am\n",
       "2 0        7:00pm    7     00     pm\n",
       "3 0      11:15 pm   11     15     pm\n",
       "4 0      08:10 am   08     10     am\n",
       "  1       09:00am   09     00     am"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the entire time, the hours, the minutes, and the period with group names\n",
    "df['text'].str.extractall(r'(?P<time>(?P<hour>\\d?\\d):(?P<minute>\\d\\d) ?(?P<period>[ap]m))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internationalization and Issues with Non-ASCII Characters\n",
    "#### English and ASCII\n",
    "* ASCII: American Standard Code for Information Interchange\n",
    "    * 7-bit character encoding standard: 128 valid codes\n",
    "    \n",
    "#### Other Character Encodings\n",
    "* IBM EBCDIC\n",
    "* LATIN-I\n",
    "* JIS: Japanese Industrial Standards\n",
    "* CCCII: Chinese Character Code for Information Interchange\n",
    "* EUC: Extended Unix Code\n",
    "* Unicode and UTF-8 (**Most common**)\n",
    "\n",
    "#### Unicode\n",
    "* Industry standard for encoding and representing text\n",
    "* Over 128,000 characters from 130+ scripts and symbol sets\n",
    "\n",
    "##### UTF-8\n",
    "* Unicode Transformational Format - 8-bits\n",
    "* Variable length encoding: One to four bytes\n",
    "* Backward compatible with ASCII\n",
    "    * One byte codes same as ASCII\n",
    "* Dominant character encoding for the Web\n",
    "* Default in Python 3\n",
    "    * Python3: \"Resume\"\n",
    "    * Python2: u\"Resume\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take Home Concepts\n",
    "* Diversity in Text\n",
    "* ASCII and other character encodings\n",
    "* Handling text in UTF-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: Basic Natural Language Processing\n",
    "### What is Natural Langauge Processing?\n",
    "* Any computation, manipulation of natural langauge\n",
    "* Natural langauge evolve\n",
    "    * new words get added\n",
    "    * old words lose popularity\n",
    "    * meanings of words change\n",
    "    * language rules themselves may change\n",
    "\n",
    "### NLP Tasks: A Broad Spectrum\n",
    "* Counting words, counting frequency of words\n",
    "* Finding sentence boundaries\n",
    "* Part of speech tagging\n",
    "* Parsing the sentence structure\n",
    "* Identifying semantic rules\n",
    "* Identifying entities in a sentence\n",
    "* Finding which pronoun refers to which entity, and many more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic NLP Tasks with NLTK\n",
    "* NKTK: Natural Langauge Toolkit\n",
    "* Open source library in Python\n",
    "* Has support for most NLP tasks\n",
    "* Also provides access to numerous text corpora\n",
    "* **More advanced tool than regular expressions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "# Import module\n",
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent1: Call me Ishmael .\n",
      "sent2: The family of Dashwood had long been settled in Sussex .\n",
      "sent3: In the beginning God created the heaven and the earth .\n",
      "sent4: Fellow - Citizens of the Senate and of the House of Representatives :\n",
      "sent5: I have a problem with people PMing me to lol JOIN\n",
      "sent6: SCENE 1 : [ wind ] [ clop clop clop ] KING ARTHUR : Whoa there !\n",
      "sent7: Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
      "sent8: 25 SEXY MALE , seeks attrac older single lady , for discreet encounters .\n",
      "sent9: THE suburb of Saffron Park lay on the sunset side of London , as red and ragged as a cloud of sunset .\n"
     ]
    }
   ],
   "source": [
    "sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting Vocabulary of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Wall Street Journal>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words\n",
    "len(sent7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100676"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Letters\n",
    "len(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12408"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique words\n",
    "len(set(text7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high-technology',\n",
       " 'Navy',\n",
       " 'contain',\n",
       " '434.4',\n",
       " 'Avrett',\n",
       " 'T-shirts',\n",
       " 'Economy',\n",
       " 'Society',\n",
       " 'buoyed',\n",
       " 'indicate']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First ten words\n",
    "list(set(text7))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12408"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency distribution\n",
    "dist = FreqDist(text7)\n",
    "len(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre', 'Vinken', ',', '61', 'years', 'old', 'will', 'join', 'the', 'board']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab1 = dist.keys()\n",
    "#vocab1[:10] \n",
    "# In Python 3 dict.keys() returns an iterable view instead of a list\n",
    "list(vocab1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist['four']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['billion',\n",
       " 'company',\n",
       " 'president',\n",
       " 'because',\n",
       " 'market',\n",
       " 'million',\n",
       " 'shares',\n",
       " 'trading',\n",
       " 'program']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restriction on the length of the word is important to avoid meaningless words.\n",
    "freqwords = [w for w in vocab1 if len(w) > 5 and dist[w] > 100]\n",
    "freqwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization\n",
    "* Differenct forms of the same \"word\"\n",
    "\n",
    "##### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'listed', 'lists', 'listing', 'listings']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization\n",
    "input1 = \"List listed lists listing listings\"\n",
    "words1 = input1.lower().split(' ')\n",
    "words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'list', 'list', 'list', 'list']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract stem\n",
    "porter = nltk.PorterStemmer()\n",
    "[porter.stem(t) for t in words1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Universal',\n",
       " 'Declaration',\n",
       " 'of',\n",
       " 'Human',\n",
       " 'Rights',\n",
       " 'Preamble',\n",
       " 'Whereas',\n",
       " 'recognition',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inherent',\n",
       " 'dignity',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalienable',\n",
       " 'rights',\n",
       " 'of']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "udhr[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['univers',\n",
       " 'declar',\n",
       " 'of',\n",
       " 'human',\n",
       " 'right',\n",
       " 'preambl',\n",
       " 'wherea',\n",
       " 'recognit',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inher',\n",
       " 'digniti',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalien',\n",
       " 'right',\n",
       " 'of']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(t) for t in udhr[:20]] # Still Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatization\n",
    "* Lemmatization: Stemming, but resulting stems are all valid words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Universal',\n",
       " 'Declaration',\n",
       " 'of',\n",
       " 'Human',\n",
       " 'Rights',\n",
       " 'Preamble',\n",
       " 'Whereas',\n",
       " 'recognition',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inherent',\n",
       " 'dignity',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalienable',\n",
       " 'right',\n",
       " 'of']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "[WNlemma.lemmatize(t) for t in udhr[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization\n",
    "* Spliting a sentence into words/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children', \"shouldn't\", 'drink', 'a', 'sugary', 'drink', 'before', 'bed.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text11 = \"Children shouldn't drink a sugary drink before bed.\"\n",
    "text11.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NLTK has an in-bulit tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children',\n",
       " 'should',\n",
       " \"n't\",\n",
       " 'drink',\n",
       " 'a',\n",
       " 'sugary',\n",
       " 'drink',\n",
       " 'before',\n",
       " 'bed',\n",
       " '.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization separates negation and full stop\n",
    "nltk.word_tokenize(text11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* More fundamental question: what is a sentence and how do you know sentence boundaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puntuation marks separate sentences, but not all of them (e.g. $2.99.)\n",
    "text12 = \"This is the first sentence. A gallon of milk in the U.S. costs $2.99. Is this the third sentence? Yes, it is!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NLTK has an in-built sentence splitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(text12)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first sentence.',\n",
       " 'A gallon of milk in the U.S. costs $2.99.',\n",
       " 'Is this the third sentence?',\n",
       " 'Yes, it is!']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced NLP Tasks with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Descriptions of the tag names. \n",
    "nltk.help.upenn_tagset('MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "# Help\n",
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Children', 'NNP'),\n",
       " ('should', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('drink', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('sugary', 'JJ'),\n",
       " ('drink', 'NN'),\n",
       " ('before', 'IN'),\n",
       " ('bed', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text13 = nltk.word_tokenize(text11)\n",
    "nltk.pos_tag(text13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* POS tagging allows you to group multiple words into a single category according to their part of speech\n",
    "* Useful for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ambiguity in POS Tagging\n",
    "* Ambiguity is common in English\n",
    "* e.g. \"Visiting aunts can be a nuisance\" has two meaings:\n",
    "    * \"Aunts\" who are visiting can be nuisance.\n",
    "    * The act of \"visiting\" aunts can be nuisance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Visiting', 'VBG'),\n",
       " ('aunts', 'NNS'),\n",
       " ('can', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('nuisance', 'NN')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text14 = nltk.word_tokenize(\"Visiting aunts can be a nuisance\")\n",
    "nltk.pos_tag(text14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* POS tagging points only one sort of tag though \"visiting\" can be either adjectives or gerend.\n",
    "* The probability of finding \"visiting\" as an adjective is lower so the gerend winds up, though the alternative is still valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Alice) (VP (V loves) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "# Parsing sentence structure\n",
    "text15 = nltk.word_tokenize(\"Alice loves Bob\")\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP\n",
    "NP -> 'Alice' | 'Bob'\n",
    "V -> 'loves'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "trees = parser.parse_all(text15)\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ambiguity in Parsing\n",
    "* Ambiguity may exist even if sentences are grammatically correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Grammar with 13 productions>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preposition attachment problem\n",
    "text16 = nltk.word_tokenize(\"I saw the man with a telescope\")\n",
    "grammar1 = nltk.data.load('mygrammar.cfg')\n",
    "grammar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Det the) (N man)))\n",
      "    (PP (P with) (NP (Det a) (N telescope)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det the) (N man) (PP (P with) (NP (Det a) (N telescope))))))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammar1)\n",
    "trees = parser.parse_all(text16)\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK and Parse Tree Collection\n",
    "* Grammar check requires much manuel work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP Pierre) (NNP Vinken))\n",
      "    (, ,)\n",
      "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (MD will)\n",
      "    (VP\n",
      "      (VB join)\n",
      "      (NP (DT the) (NN board))\n",
      "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
      "      (NP-TMP (NNP Nov.) (CD 29))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "text17 = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "print(text17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS Tagging and Parsing Ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'), ('old', 'JJ'), ('man', 'NN'), ('the', 'DT'), ('boat', 'NN')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncommon usages of words\n",
    "text18 = nltk.word_tokenize(\"The old man the boat\")\n",
    "nltk.pos_tag(text18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Colorless', 'NNP'),\n",
       " ('green', 'JJ'),\n",
       " ('ideas', 'NNS'),\n",
       " ('sleep', 'VBP'),\n",
       " ('furiously', 'RB')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Well-formed sentences may still be meaningless\n",
    "text19 = nltk.word_tokenize(\"Colorless green ideas sleep furiously\")\n",
    "nltk.pos_tag(text19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take Home Concepts\n",
    "* POS tagging provides insights into the word classes/types in a sentence.\n",
    "* Parsing the grammatical structures helps derive meaning.\n",
    "* Both tasks are difficult, liguistic ambiguity increases the difficulty even more.\n",
    "* Better models could be learned with supervised learning\n",
    "* NLTK provides access to tools and data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3: Text Classification\n",
    "### Classification\n",
    "* Assigning of the correct class label to the given input, given a set of classes.\n",
    "* Examples\n",
    "    * Topic Identification\n",
    "    * Spam Detection\n",
    "    * Sentiment Analysis\n",
    "    * Spelling Correction\n",
    "* Classification is a supervised learning from past instances.\n",
    "\n",
    "#### Supervised Classification\n",
    "* Learn a <font color=\"red\">classification model</font> on properties (\"features\") and their importance(\"weights\") from labeled instances. \n",
    "    * X: Set of attributes or features {x1, x2, ..., xn}\n",
    "    * Y: A \"class\" label from the label set {y1, y2, ..., yk}\n",
    "* Apply the model on new instances to predict the label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Paradigms\n",
    "* When there are only two possible classes; |Y| = 2:\n",
    "<center><font color=\"red\">Binary Classification</font></center>\n",
    "* When there are more than two possible classes; |Y| > 2:\n",
    "<center><font color=\"red\">Multi-classification</font></center>\n",
    "* When data instances can have two or more labels:\n",
    "<center><font color=\"red\">Multi-label Classification</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions to Ask in Supervised Learning?\n",
    "* Traning Phase\n",
    "    * What are the features? How do you represent them?\n",
    "    * What is the classification model/algorithm?\n",
    "    * What are the model parameters?\n",
    "    \n",
    "* Inference Phase\n",
    "    * What is the expected performance? What is a good measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Features from Text\n",
    "#### Why is Textual Data Unique?\n",
    "* Textual data presents a unique set of challenges\n",
    "* All the information you need is in the text\n",
    "* But features can be pulled out from text at different granularities.\n",
    "\n",
    "#### Types of Textual Features\n",
    "* Words\n",
    "    * By far the most common class of features\n",
    "    * Handling commonly-occurring words: Stop words\n",
    "    * Normalization: Make lower case vs. leave as-is\n",
    "    * Stemming / Lemmatization\n",
    "    * Characteristics of words: Capitalization\n",
    "    * Parts of speech of words in a sentence\n",
    "    * Grammatical structure, sentence parsing\n",
    "    * Grouping words of similar meaning, semantics\n",
    "        * {buy, purchase}\n",
    "        * {Mr., Ms., Dr., Pror.}; Numbers / Digits; Dates \n",
    "    * Depending on classification tasks, features my come from inside words and word sequence\n",
    "        * bigrams, trigrams, n-grams: \"White House\"\n",
    "        * Character sub-sequences in words: \"ing\", \"ion\", ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifiers\n",
    "#### Probabilistic Model\n",
    "* Update the likelihood of the class given new information\n",
    "    * e.g. Python (zoology) / Python download (computer science)\n",
    "* <font color='red'>Prior Probability</font>: Pr(y=<font color='green'>Entertainment</font>), Pr(y=<font color='green'>Computer Science</font>), Pr(y=<font color='green'>Zoology</font>)\n",
    "* <font color='red'>Posterior Probability</font>: Pr(y=<font color='green'>Entertainment</font>|x=<font color='blue'>\"Python\"</font>)\n",
    "\n",
    "#### Bayes's Rule\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/87c061fe1c7430a5201eef3fa50f9d00eac78810\">\n",
    "\n",
    "* <font color=\"red\">Naive assumption</font>: Given the class label, features are assumed to be independent of each other\n",
    "--- \n",
    "* y* = argmax(y) Pr(y|X) = argmax(y) Pr(y) * Pr(X|y)  \n",
    "* y* = argmax(y) Pr(y|X) = argmax(y) Pr(y) * âˆ Pr(xi|y)\n",
    "\n",
    "#### Parameters\n",
    "* Prior probabilities: Pr(y) for all y in Y\n",
    "* Likelihood: Pr(xi|y) for all features xi and labels y in Y\n",
    "* If there are 3 classes (|Y|=3) and 100 features in X, how many parameters does Naive Bayes models have?\n",
    "    * 3 + 2 * 3 * 100\n",
    "    \n",
    "#### Learning Parameters\n",
    "* Prior probabilities: Pr(y) for all y in Y\n",
    "    * From training data\n",
    "    * Count the number of instances in each class\n",
    "    * If there are N instances in all, and n out of those are labeled as class y: Pr(y) = n / N\n",
    "    \n",
    "* Likelihood: Pr(xi|y) for all features xi and labels y in Y\n",
    "    * Count how many times fetures xi appears in instances labeled as class y\n",
    "    * If there are p instances of class y, and xi appears in k of those, Pr(xi|y) = k / p\n",
    "    \n",
    "#### Smoothing\n",
    "* What happens if Pr(xi|y) = 0?\n",
    "    * Feature xi never occurs in documents labeled y\n",
    "    * But then, the posterior probability Pr(y|xi) will be 0\n",
    "    * Instead, smooth the parameters\n",
    "    * <font color='red'>Laplace smoothing</font> or <font color='red'>Additive smoothing</font>: Add a dummy count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "* Please refer to [Support Vector Machine](https://github.com/Jiseong-Michael-Yang/Machine-Learning/blob/master/Support%20Vector%20Machines.md)\n",
    "> You may have to install additional plug-in such as from this [link](https://chrome.google.com/webstore/detail/mathjax-plugin-for-github/ioemnmodlmafdkllaclgeombjnmnbima?hl=en) to properly render the page, though some elements may still be unavailable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Text Classifiers in Python\n",
    "* Toolkits for Supervised Text Classification\n",
    "    * Scikit-learn\n",
    "    * NLTK\n",
    "        * Interfaces with sklearn and other ML toolkits (like Weka)\n",
    "\n",
    "#### Scikit-learn\n",
    "* Open-source Machine Learning library\n",
    "* Started as Google Summer of Code by Dave Cournapeau, 2007\n",
    "* It has a more programmatic interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ece050054c25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mclfrNB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Test the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "# Choose the classifier\n",
    "clfrNB = naive_bayes.MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "clfrNB.fit(train_data, train_labels)\n",
    "\n",
    "# Test the model\n",
    "predicted_labels = clfrNB.predict(test_data)\n",
    "\n",
    "# Check the result\n",
    "metrics.f1_score(test_labels, predicted_labels, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn import svm\n",
    "\n",
    "# Choose the classifier: linear kernel is typically used for text classification\n",
    "clfrSVM = svm.SVC(kernel='linear', c=0.1)\n",
    "\n",
    "# Train the model\n",
    "clfrSVM.fit(train_data, train_labels)\n",
    "\n",
    "# Test the model\n",
    "predicted_labels = clfrSVM.predict(test_data)\n",
    "\n",
    "# Check the result\n",
    "metrics.f1_score(test_labels, predicted_labels, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Selection in Scikit-learn\n",
    "* train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = \n",
    "model_selection.train_test_split(train_data, train_labels,\n",
    "                                 test_size = 0.333, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cross-validation\n",
    "    * K iterations of training in K-fold cross-validation\n",
    "    * Get the average out\n",
    "    * Very common to use 10-fold cross-validation when the data set is large (training: test = 9: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = \n",
    "model_selection.train_test_split(train_data, train_labels,\n",
    "                                 test_size = 0.333, random_state = 0)\n",
    "\n",
    "predicted_labels = model_selection.cross_val_predict(clfrSVM, train_data, train_lables, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK\n",
    "* NLTK has some classification algorithms\n",
    "    * NaiveBayesClassifier\n",
    "    * DecsionTreeClassifier\n",
    "    * ConditionalExponentialCLassifier\n",
    "    * MaxtentClassifier\n",
    "    * WekaClassifier\n",
    "    * SklearnClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "# Choose the classifier\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Train the model\n",
    "classifier.classify(unlabeled_instance)\n",
    "classifier.classify_many(unlabeled_instances)\n",
    "\n",
    "# Test the model\n",
    "nltk.classify.util.accuracy(classifier, test_set)\n",
    "\n",
    "# Shows all the labels the classifier has trained on\n",
    "classifier.labels()\n",
    "\n",
    "# Shows the most important/informative feature\n",
    "classifier.show_most_informative_features()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SklearnClassifier\n",
    "* Sklearn does not have a native SVM function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Choose the model\n",
    "clfrNB = SklearnClassifier(MultinomialNB()).train(train_set)\n",
    "clfrSVM = SklearnClassifier(SVC(), kerner='linear').train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4: Topic Modeling\n",
    "### Semantic Text Similarity\n",
    "#### Application of Semantic Similarity\n",
    "* Grouping similar words into semantic concepts\n",
    "* As a building block in natural language understanding tasks\n",
    "    * Textual entailment: the smaller or one of the two sentences derives its meaning or entails its meaning from another piece of text\n",
    "    * Paraphrasing: a task where you rephrase or rewrite some sentence into another sentence that has the same meaning\n",
    "\n",
    "#### WordNet\n",
    "* WordNet\n",
    "    * Semantic dictionary of (mostly) English words, interlinked by semantic relations\n",
    "    * Includes rich linguistic information\n",
    "        * Part of speech, word senses, synonyms, hypernyms/hyponyms, meronyms, derivationally related forms et cetera\n",
    "    * Machine-readable, freely available\n",
    "\n",
    "* Semantic Similarity Using WordNet\n",
    "    * WordNet organizes information in a hierarchy\n",
    "    * Many similarity measures use the hierarchy in some way\n",
    "    * Verbs, nounds, and adjectives all have separate hierarchies\n",
    "\n",
    "#### Measures of Similarity  \n",
    "<img src=\"./img/word_hierarchy.jfif\" width=500 />  \n",
    "  \n",
    "##### Path Similarity  \n",
    "  * Find the shortest path between the two concepts\n",
    "  * Similarity measure inversely related to path distance\n",
    "      * PathSim(deer, elk) = 0.5 ($\\frac{1}{1+1}$)\n",
    "      * PathSim(deer, giraffe) = 0.33 ($\\frac{1}{2+1}$)\n",
    "      * PathSim(deer, horse) = 0.14 ($\\frac{1}{6+1}$)\n",
    "      \n",
    "##### Lowest Common Subsumer (LCS)\n",
    "* Find the closest ancestor to both concepts\n",
    "    * LCS(deer, elk) = deer\n",
    "    * LCS(deer, giraffe) = ruminant\n",
    "    * LCS(deer, horse) = ungulate\n",
    "* Lin Similarity\n",
    "    * Ratio of the amount of information needed to state the commonality between two concepts and the information neede to fully describe these terms\n",
    "        * $LinSim(u,v) = \\frac{2\\log(P(LCS(u,v))}{\\log(P(u))+\\log(P(v))}= \\frac{2\\log{\\frac{N}{df(LCS(u,v))}}}{log{\\frac{N}{df(u)}}+log{\\frac{N}{df(u)}}} =\\frac{2\\text{LCS(u,v)'s amount of information}}{\\text{u's amount of information + v's amount of information}}$\n",
    "        * When LCS of words occur often, it could be an indicator of their similarity, however, this may only due to its frequency itself. \n",
    "            * Therefore, it needs to be normalized by diving the value with the frequency of each word\n",
    "        * $P(u), P(v)$ are given by the information content learnt over a large corpus\n",
    "        > * Random Variable X's Amount of Information is greater when X is not so obvious to take place\n",
    "        > * $-\\log{\\frac{1}{P(X)}} = -\\log{P(X)} = \\log{\\frac{N}{*df}}$ (*: frequency of the documents where x occurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Measures of Similarity In Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ì–‘ì§€ì„±\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     C:\\Users\\ì–‘ì§€ì„±\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7726998936065773"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WordNet easily imported into Python through NLTK\n",
    "import nltk\n",
    "nltk.download([\"wordnet\", \"wordnet_ic\"])\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Find appropriate senses of the words: give sense to words: get the \"first\" synonym of the \"noun\", \"deer/elk\"\n",
    "deer = wn.synset('deer.n.01')\n",
    "elk = wn.synset('elk.n.01')\n",
    "horse = wn.synset('horse.n.01')\n",
    "\n",
    "# Find path similarity\n",
    "deer.path_similarity(elk) # 0.5\n",
    "deer.path_similarity(horse) # 0.1428...\n",
    "\n",
    "# Use an information criteria to find Lin similarity\n",
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat') # Criteria\n",
    "\n",
    "# This measure does not explicitly use the distance between two concepts\n",
    "deer.lin_similarity(elk, brown_ic) # 0.7726...\n",
    "deer.lin_similarity(horse, brown_ic) # 0.8623...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collocations and Distributional Similarity\n",
    "* Collocations\n",
    "    * \"You know a word by the company it keeps\" [Firth, 1957]\n",
    "    * Two words that frequently appears in similar contexts are more likely to be semantically related\n",
    "        * The friends <u>met</u> <u>at</u> <u>a</u> <font color=\"red\">cafÃ©</font>.\n",
    "        * Shyam <u>met</u> Ray <u>at</u> <u>a</u> <font color=\"red\">pizzeria</font>.\n",
    "        * Let's <u>meet</u> up <u>near</u> <u>the</u> <font color=\"red\">coffe shop</font>.\n",
    "        * The secret <u>meeting</u> <u>at</u> <u>the</u> <font color=\"red\">restaurant</font> soon became public.\n",
    "* Distributional Similarity: Context\n",
    "    * Words before, after, within a small window\n",
    "    * Part of speech of words before, after, in a small window\n",
    "    * Specific syntatic relation to the target word\n",
    "    * Words in the same sentence, same documents, ...\n",
    "* Strength of Association between Words\n",
    "    * How frequently are these?\n",
    "        * Not similar if two words don't occur together often\n",
    "    * Also important to see how frequent individual words are\n",
    "        * 'the' is very frequent, so high chances it co-occurs often with every other word (needs to be **normalized**)\n",
    "        * Pointwise Mutual Information\n",
    "            * $PMI(w,c)=\\log{\\left[\\frac{P(w,c)}{P(w)P(c)}\\right]}$\n",
    "            * [To be added](https://bab2min.tistory.com/605)\n",
    "            * Probability of \"words together on the context\" divided by \"that of occuring independently\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collocations and Distributional Similarity in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NLTK Collocations and Association measures\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "# Learn based on the text\n",
    "finder = BigramCollocationFinder.from_words(text) # Text variable input\n",
    "\n",
    "# Get top ten pairs of collocated words using PMI measures\n",
    "finder.nbest(bigram_measures.pmi, 10) # finder also has other useful functions, such as frequency filter\n",
    "\n",
    "# Filter any pairs that occur less than ten times in the corpus\n",
    "finder.apply_freq_filter(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Take Home Concepts\n",
    "    * Finding similarity between words and text is non-trivial\n",
    "    * WordNet is a useful resource for semantic relationships between words\n",
    "    * Many similarity function exist\n",
    "    * NLTK is a useful package for many such tasks   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "#### Underlying Idea\n",
    "* Latent Dirichlet Allocation (Blei et al., '03)  \n",
    "    <img src=\"./img/topic_modeling_example.jfif\" width = 500 />  \n",
    "    * Topic 1: Genetics (gene, sequence, genome, ...)\n",
    "    * Topic 2: Computation (number, computer, analysis, ...)\n",
    "    * Topic 3: Life Sciences (life, survive, organism, ...)\n",
    "    * Topic 4: Anatomy (brain, neuron, nerve, ...)\n",
    "         \n",
    "* Intuition: Documents as a Mixture of Topics\n",
    "<img src=\"./img/topic_modeling_intuition.jfif\" width = 500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modeling\n",
    "* Topic Modeling\n",
    "    * A coarse-level analysis of what's in a text collection\n",
    "    * Topic: the subject (theme) of a discourse\n",
    "    * Topics are represented as a word distribution\n",
    "        * For a particular word, there are different distribution of probability occuring from a topic\n",
    "        * Topics are basically this probability distribution over all words\n",
    "        \n",
    "* Information for Topic Modeling\n",
    "    * Known information\n",
    "        * The text collection or corpus\n",
    "        * Number of topics\n",
    "    * Unknown information\n",
    "        * The actual topics\n",
    "        * Topic distribution for each document\n",
    "\n",
    "* Essentially, Topic Modeling is text clustering problem\n",
    "    * Documents and words clustered simultaneously\n",
    "   \n",
    "* Different topic modeling approaches available\n",
    "    * Probabilistic Latent Semantic Analysis (PLSA) [Hoffman '99]\n",
    "    * Latent Dirichlet Allocation (LDA) [Blei, Ng, and Jordan, '03]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative Models\n",
    "\n",
    "##### Simple Generative Model for Text (Unigram Model)\n",
    "<img src=\"./img/simple_generative_model.jfif\" width = 500 />\n",
    "<center>$Pr(text|model)$</center>\n",
    "\n",
    "* Suppose we have a magic chest that gives out words\n",
    "* We use those words coming from the chest to generate a document\n",
    "* Reversely, we create a probability distribution of how likely it is to see these words\n",
    "\n",
    "##### Generative Model Can Be Complex (Mixture Model)\n",
    "<img src=\"./img/complex_generative_model.jfif\" width = 500 />\n",
    "<center>$Pr(text|model)$</center>\n",
    "\n",
    "* Suppose we have several chests that give out words\n",
    "* We use randomly coming-out words to generate the **same document** we created in the simple model\n",
    "* Reversely, we could not only figure out what were **the individual topic models and individual word distributions**, but also this mixture model of how you use these **four topic models and combine them with different _proportions_** to create one document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation (LDA)\n",
    "##### Generative model for a document _d_\n",
    "* Choose length of document _d_\n",
    "* Choose a mixture of topics for document _d_\n",
    "* Use a topic's multinomial distribution to output words to fill that topic's quota\n",
    "    \n",
    "##### [Latent Dirichlet Allocation for Topic Modeling](https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/)\n",
    "* LDA is a matrix factorization\n",
    "* In vector space, any corpus (collection of documents) can be presented as a DTM\n",
    "***\n",
    "* The following matrix shows a corpus of N documents $D_1, D_2, D_3, \\ldots , D_N$ and vocabulary size of M words $W_1, W_2, W_3, \\ldots , W_M$\n",
    "* The value of $cell_{ij}$ gives the frequency count of word $W_j$ in Document $D_i$\n",
    "    \n",
    "|(N,M)|$W_1$|$W_2$|$W_3$|$\\cdots$|$W_M$|\n",
    "|-|-|-|-|-|-|\n",
    "|$D_1$|0|2|1|$\\cdots$|3|\n",
    "|$D_2$|1|4|0|$\\cdots$|0|\n",
    "|$D_3$|0|2|3|$\\cdots$|1|\n",
    "|$\\vdots$|$\\vdots$|$\\vdots$|$\\vdots$|$\\ddots$|$\\vdots$\n",
    "|$D_N$|1|1|3|$\\cdots$|0|\n",
    "\n",
    "* LDA converts this DTM into two lower dimensional matrices\n",
    "    * $\\text{M1 (N,K)}$\n",
    "    * $\\text{M2 (K,M)}$\n",
    "* $M1$ is a **document-topics matrix** \n",
    "    \n",
    "|(N,K)|$K_1$|$K_2$|$K_3$|$\\cdots$|$K_K$|\n",
    "|-|-|-|-|-|-|\n",
    "|$D_1$|1|0|0|$\\cdots$|1|\n",
    "|$D_2$|1|1|0|$\\cdots$|0|\n",
    "|$D_3$|1|0|0|$\\cdots$|1|\n",
    "|$\\vdots$|$\\vdots$|$\\vdots$|$\\vdots$|$\\ddots$|$\\vdots$\n",
    "|$D_N$|1|0|1|$\\cdots$|0|\n",
    "    \n",
    "* $M2$ is a **topic-terms matrix**\n",
    "\n",
    "|(K,M)|$W_1$|$W_2$|$W_3$|$\\cdots$|$W_M$|\n",
    "|-|-|-|-|-|-|\n",
    "|$K_1$|0|1|1|$\\cdots$|1|\n",
    "|$K_2$|1|1|1|$\\cdots$|0|\n",
    "|$K_3$|1|0|0|$\\cdots$|1|\n",
    "|$\\vdots$|$\\vdots$|$\\vdots$|$\\vdots$|$\\ddots$|$\\vdots$\n",
    "|$K_K$|1|1|0|$\\cdots$|0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These two matrices already provides topic word and document topic distributions, but need to be improved by LDA\n",
    "    * LDA makes use of sampling techniques in order to improve these matrices\n",
    "    * It iterates through each word $w$ for each document $d$ and it tries to adjust the current topic\n",
    "    * A new topic $k$ is assigned to word $w$ with a probability $P(=P_1{\\cdot}P_2)$"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For every topic, two possibilities $P_1$ and $P_2$ are calculated\n",
    "    * $P_1=P(\\text{topic t}|\\text{document d})$: the proportion of words in document $d$ that are currently assigned to topic $t$\n",
    "    * $P_2=P(\\text{word w}|\\text{topic t})$: the proportion of assignments to topic $t$ over all documents that contain word $w$\n",
    "\t\t\t\t\t\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The current topic - word assignment is updated with a new topic with the probability($P_1{\\cdot}P_2)$\n",
    "    * The model assumes that all the existing word(topic assignments) except the current word are correct\n",
    "    * This is essentially the probability that topic $t$ generated word $w$\n",
    "\n",
    "* After a number of iterations, a steady state is achieved where the document topic and topic term distributions are fairly good(**the convergence of LDA**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modeling in Practice\n",
    "* How many topics?\n",
    "    * Finding or even guessing the number of topic is hard\n",
    "    * If one is knowledgable of a specific domain, it would give a good sense to pick the number\n",
    "* Interpreting Topics\n",
    "    * Topics are just word distributions\n",
    "    * Making sense of words / generating labels is **subjective** \n",
    "\n",
    "##### Working with LDA in Python\n",
    "   * Many packages availbable, such as gensim, lda\n",
    "   * Pre-processing text\n",
    "       * Tokenize, normalize (lowercase)\n",
    "       * Stop word removal (also if some words are commonly used across documents of a specific topic)        \n",
    "       * Stemming\n",
    "       * Convert tokenized documents to a document-term matrix\n",
    "       * Build LDA models on the DTM\n",
    "   * ldamodel can also be used to find topic distribution of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'doc_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-86e11c711883>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Dictionary is mapping between IDs and words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_set\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# doc_set: set of pre-processed text documents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Create DTM with all the documents in doc_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc_set' is not defined"
     ]
    }
   ],
   "source": [
    "# Gensim is a libarary for topic modeling, document indexing, and similarity retrieval with large corpora\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Dictionary is mapping between IDs and words\n",
    "dictionary = corpora.Dictionary(doc_set) # doc_set: set of pre-processed text documents\n",
    "\n",
    "# Create DTM with all the documents in doc_set\n",
    "corpus = [dictionary.doc2bow(doc) for doc in doc_set]\n",
    "\n",
    "# Input DTM to LDA model\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=4, id2word=dictionary, passes=50)\n",
    "\n",
    "# Print the topics\n",
    "print(ldamodel.print_topics(num_topics=4, num_words=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Take Home Concepts\n",
    "* Topic modeling is **an explanatory tool** frequently used for text mining\n",
    "* Latent Dirichlet Allocation is a generative model used extensively for modeling large text corpora\n",
    "* LDA can also be used as a **feature selection technique for text classification** and other tasks\n",
    "    * Remove all **common** features coming from corpus\n",
    "    * Focus on **features** on specific topics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information Extraction\n",
    "##### Information is Hidden in Free-text\n",
    "* Most traditional transactional information is structured\n",
    "* Abundance of unstructured or freeform text are growing (80% of data)\n",
    "* The key is to convert unstructured text to structured form\n",
    "\n",
    "##### Information Extraction\n",
    "* Goal: identify and extract fields of interest from free text\n",
    "    * Headlines\n",
    "    * Author\n",
    "    * Reviewer\n",
    "    * Published date\n",
    "    * Publisher\n",
    "    \n",
    "##### Fields of Interest\n",
    "* Named entities\n",
    "    * Noun phrases that are of speicific type and refer to specific individuals, places, organizations, ...\n",
    "        * **<font color='red'>News</font>** People, Places, Dates, ...\n",
    "        * **<font color='red'>Finance</font>** Money, Companies, ...\n",
    "        * **<font color='red'>Medicine</font>** Diseases, Drugs, Procedures, ...\n",
    "    * Recognition: Technique(s) to identify all mentions of pre-defiend names entities in text\n",
    "        * Identify the mention / phrases: Boundary detection\n",
    "        * Identify the type: Tagging / classification\n",
    "    * Examples of Named Entity Recognition Tasks  \n",
    "    <img src=\"./img/entity_recognition_example.jpg\" width=500 />\n",
    "    * Approaches to Identify Named Entities\n",
    "        * Depends on kinds of entities that need to be identified\n",
    "        * For well-formatted fields like date, phone numbers: **Regular expressions**\n",
    "        * For other fields: typically a machine learning approach\n",
    "    * Person, Organization, Location/GPE\n",
    "        * Standard NER task in NLP research community\n",
    "        * Typically a four-class model\n",
    "            * PER\n",
    "            * ORG\n",
    "            * LOC / GPE\n",
    "            * Other / Outside (any other class)\n",
    "                * e.g. John **met(Outside)** Brinda\n",
    "\n",
    "* Relation Extraction\n",
    "    * Identify relationships between named entities\n",
    "        * Erbitux helps treat lung cancer\n",
    "            * Erbitux $-(\\text{treats})\\rightarrow$ lung cancer\n",
    "            * Lung cancer $-(\\text{is treated by})\\rightarrow$ Erbitux\n",
    "    * What happened to who, when, where, ...\n",
    "    \n",
    "* Co-reference Resolution\n",
    "    * Disambiguate mentions and group mentions together\n",
    "        * <font color='blue'>Anita</font> met <font color='red'>Joseph</font> at the market. <font color='red'>He surprised <font color='blue'>her</font> with a rose.\n",
    "    \n",
    "* Question Answering\n",
    "    * Given a question, find the most appropriate answer from the text\n",
    "        * What does Erbitux treat?\n",
    "        * Who gave Anita the rose?\n",
    "    * Builds on named entity recognition, relation extraction, and co-reference resolution\n",
    "\n",
    "##### Take Home Concepts\n",
    "* Information Extraction is important for natural language understanding and making sense of textual data\n",
    "* Named Entity Recognition is a key building block to address many advanced NLP tasks\n",
    "* Named Entity Recognition systems extensively deploy supervised machine learning and text mining techniques discussed in this course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "466px",
    "left": "21px",
    "top": "110px",
    "width": "260.653px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
